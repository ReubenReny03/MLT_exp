{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4 combinations | Sampling itemset size 43\n",
      "Frequent Itemsets:\n",
      "     support                       itemsets\n",
      "0     0.875                        (bread)\n",
      "1     0.750                       (butter)\n",
      "2     0.250                       (cheese)\n",
      "3     0.625                         (milk)\n",
      "4     0.625                (bread, butter)\n",
      "5     0.250                (bread, cheese)\n",
      "6     0.625                  (bread, milk)\n",
      "7     0.250               (butter, cheese)\n",
      "8     0.375                 (butter, milk)\n",
      "9     0.125                 (cheese, milk)\n",
      "10    0.250        (bread, butter, cheese)\n",
      "11    0.375          (bread, butter, milk)\n",
      "12    0.125          (bread, cheese, milk)\n",
      "13    0.125         (butter, cheese, milk)\n",
      "14    0.125  (bread, butter, cheese, milk)\n",
      "\n",
      "Association Rules:\n",
      "                antecedents      consequents  antecedent support  \\\n",
      "0                  (bread)         (butter)               0.875   \n",
      "1                 (butter)          (bread)               0.750   \n",
      "2                 (cheese)          (bread)               0.250   \n",
      "3                  (bread)           (milk)               0.875   \n",
      "4                   (milk)          (bread)               0.625   \n",
      "5                 (cheese)         (butter)               0.250   \n",
      "6          (bread, cheese)         (butter)               0.250   \n",
      "7         (butter, cheese)          (bread)               0.250   \n",
      "8                 (cheese)  (bread, butter)               0.250   \n",
      "9           (butter, milk)          (bread)               0.375   \n",
      "10          (cheese, milk)          (bread)               0.125   \n",
      "11          (cheese, milk)         (butter)               0.125   \n",
      "12   (bread, cheese, milk)         (butter)               0.125   \n",
      "13  (butter, cheese, milk)          (bread)               0.125   \n",
      "14          (cheese, milk)  (bread, butter)               0.125   \n",
      "\n",
      "    consequent support  support  confidence      lift  leverage  conviction  \\\n",
      "0                0.750    0.625    0.714286  0.952381 -0.031250      0.8750   \n",
      "1                0.875    0.625    0.833333  0.952381 -0.031250      0.7500   \n",
      "2                0.875    0.250    1.000000  1.142857  0.031250         inf   \n",
      "3                0.625    0.625    0.714286  1.142857  0.078125      1.3125   \n",
      "4                0.875    0.625    1.000000  1.142857  0.078125         inf   \n",
      "5                0.750    0.250    1.000000  1.333333  0.062500         inf   \n",
      "6                0.750    0.250    1.000000  1.333333  0.062500         inf   \n",
      "7                0.875    0.250    1.000000  1.142857  0.031250         inf   \n",
      "8                0.625    0.250    1.000000  1.600000  0.093750         inf   \n",
      "9                0.875    0.375    1.000000  1.142857  0.046875         inf   \n",
      "10               0.875    0.125    1.000000  1.142857  0.015625         inf   \n",
      "11               0.750    0.125    1.000000  1.333333  0.031250         inf   \n",
      "12               0.750    0.125    1.000000  1.333333  0.031250         inf   \n",
      "13               0.875    0.125    1.000000  1.142857  0.015625         inf   \n",
      "14               0.625    0.125    1.000000  1.600000  0.046875         inf   \n",
      "\n",
      "    zhangs_metric  \n",
      "0       -0.285714  \n",
      "1       -0.166667  \n",
      "2        0.166667  \n",
      "3        1.000000  \n",
      "4        0.333333  \n",
      "5        0.333333  \n",
      "6        0.333333  \n",
      "7        0.166667  \n",
      "8        0.500000  \n",
      "9        0.200000  \n",
      "10       0.142857  \n",
      "11       0.285714  \n",
      "12       0.285714  \n",
      "13       0.142857  \n",
      "14       0.428571  \n",
      "\n",
      "High Confidence Rules:\n",
      "                antecedents      consequents  antecedent support  \\\n",
      "1                 (butter)          (bread)               0.750   \n",
      "2                 (cheese)          (bread)               0.250   \n",
      "4                   (milk)          (bread)               0.625   \n",
      "5                 (cheese)         (butter)               0.250   \n",
      "6          (bread, cheese)         (butter)               0.250   \n",
      "7         (butter, cheese)          (bread)               0.250   \n",
      "8                 (cheese)  (bread, butter)               0.250   \n",
      "9           (butter, milk)          (bread)               0.375   \n",
      "10          (cheese, milk)          (bread)               0.125   \n",
      "11          (cheese, milk)         (butter)               0.125   \n",
      "12   (bread, cheese, milk)         (butter)               0.125   \n",
      "13  (butter, cheese, milk)          (bread)               0.125   \n",
      "14          (cheese, milk)  (bread, butter)               0.125   \n",
      "\n",
      "    consequent support  support  confidence      lift  leverage  conviction  \\\n",
      "1                0.875    0.625    0.833333  0.952381 -0.031250        0.75   \n",
      "2                0.875    0.250    1.000000  1.142857  0.031250         inf   \n",
      "4                0.875    0.625    1.000000  1.142857  0.078125         inf   \n",
      "5                0.750    0.250    1.000000  1.333333  0.062500         inf   \n",
      "6                0.750    0.250    1.000000  1.333333  0.062500         inf   \n",
      "7                0.875    0.250    1.000000  1.142857  0.031250         inf   \n",
      "8                0.625    0.250    1.000000  1.600000  0.093750         inf   \n",
      "9                0.875    0.375    1.000000  1.142857  0.046875         inf   \n",
      "10               0.875    0.125    1.000000  1.142857  0.015625         inf   \n",
      "11               0.750    0.125    1.000000  1.333333  0.031250         inf   \n",
      "12               0.750    0.125    1.000000  1.333333  0.031250         inf   \n",
      "13               0.875    0.125    1.000000  1.142857  0.015625         inf   \n",
      "14               0.625    0.125    1.000000  1.600000  0.046875         inf   \n",
      "\n",
      "    zhangs_metric  \n",
      "1       -0.166667  \n",
      "2        0.166667  \n",
      "4        0.333333  \n",
      "5        0.333333  \n",
      "6        0.333333  \n",
      "7        0.166667  \n",
      "8        0.500000  \n",
      "9        0.200000  \n",
      "10       0.142857  \n",
      "11       0.285714  \n",
      "12       0.285714  \n",
      "13       0.142857  \n",
      "14       0.428571  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Step 1: Creating synthetic data\n",
    "data = [\n",
    "    ['milk', 'bread', 'butter'],\n",
    "    ['bread', 'butter'],\n",
    "    ['milk', 'bread'],\n",
    "    ['butter'],\n",
    "    ['bread', 'butter', 'milk'],\n",
    "    ['bread', 'milk'],\n",
    "    ['milk', 'bread', 'butter', 'cheese'],\n",
    "    ['bread', 'butter', 'cheese']\n",
    "]\n",
    "\n",
    "# Step 2: Preprocessing data for Apriori Algorithm\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data).transform(data)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Step 3: Applying Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(df, min_support=0.1, use_colnames=True, verbose=1)\n",
    "\n",
    "# Step 4: Generating Association Rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Display the candidate set and frequency set for every iteration\n",
    "print(\"Frequent Itemsets:\\n\", frequent_itemsets)\n",
    "\n",
    "# Display the association rules\n",
    "print(\"\\nAssociation Rules:\\n\", rules)\n",
    "\n",
    "# Filtering rules with higher confidence values\n",
    "high_confidence_rules = rules[rules['confidence'] > 0.8]\n",
    "print(\"\\nHigh Confidence Rules:\\n\", high_confidence_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
